{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evidently Example notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import json\n",
    "\n",
    "from sklearn import datasets, ensemble, model_selection\n",
    "from scipy.stats import anderson_ksamp\n",
    "\n",
    "from evidently.dashboard import Dashboard\n",
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "from evidently.dashboard.tabs import DataDriftTab, NumTargetDriftTab, RegressionPerformanceTab\n",
    "from evidently.options import DataDriftOptions\n",
    "from evidently.model_profile import Profile\n",
    "from evidently.model_profile.sections import DataDriftProfileSection, RegressionPerformanceProfileSection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = requests.get(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\").content\n",
    "with zipfile.ZipFile(io.BytesIO(content)) as arc:\n",
    "    raw_data = pd.read_csv(arc.open(\"hour.csv\"), header=0, sep=',', parse_dates=['dteday']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.index = raw_data.apply(lambda row: datetime.datetime.combine(row.dteday.date(), datetime.time(row.hr)),\n",
    "                                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'cnt'\n",
    "prediction = 'prediction'\n",
    "numerical_features = ['temp', 'atemp', 'hum', 'windspeed', 'mnth', 'hr', 'weekday']\n",
    "categorical_features = ['season', 'holiday', 'workingday', ]#'weathersi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = raw_data.loc['2011-01-01 00:00:00':'2011-01-28 23:00:00']\n",
    "current = raw_data.loc['2011-01-29 00:00:00':'2011-02-28 23:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    reference[numerical_features + categorical_features],\n",
    "    reference[target],\n",
    "    test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = ensemble.RandomForestRegressor(random_state = 0, n_estimators = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = regressor.predict(X_train)\n",
    "preds_test = regressor.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['target'] = y_train\n",
    "X_train['prediction'] = preds_train\n",
    "\n",
    "X_test['target'] = y_test\n",
    "X_test['prediction'] = preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = ColumnMapping()\n",
    "\n",
    "column_mapping.target = 'target'\n",
    "column_mapping.prediction = 'prediction'\n",
    "column_mapping.numerical_features = numerical_features\n",
    "column_mapping.categorical_features = categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_perfomance_dashboard = Dashboard(tabs=[RegressionPerformanceTab()])\n",
    "regression_perfomance_dashboard.calculate(X_train.sort_index(), X_test.sort_index(), \n",
    "                                          column_mapping=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_perfomance_dashboard.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(reference[numerical_features + categorical_features], reference[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = ColumnMapping()\n",
    "\n",
    "column_mapping.target = target\n",
    "column_mapping.prediction = prediction\n",
    "column_mapping.numerical_features = numerical_features\n",
    "column_mapping.categorical_features = categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_prediction = regressor.predict(reference[numerical_features + categorical_features])\n",
    "reference['prediction'] = ref_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_perfomance_dashboard = Dashboard(tabs=[RegressionPerformanceTab(verbose_level=0)])\n",
    "regression_perfomance_dashboard.calculate(reference, None, column_mapping=column_mapping)\n",
    "regression_perfomance_dashboard.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some time has passed - how is the model working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_prediction = regressor.predict(current[numerical_features + categorical_features])\n",
    "current['prediction'] = current_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Week1\n",
    "regression_perfomance_dashboard.calculate(reference, current.loc['2011-01-29 00:00:00':'2011-02-07 23:00:00'], \n",
    "                                            column_mapping=column_mapping)\n",
    "regression_perfomance_dashboard.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Week2\n",
    "RegressionPerformanceTab.list_widgets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_perfomance_dashboard = Dashboard(tabs=[RegressionPerformanceTab(include_widgets=[\n",
    "    'Regression Model Performance Report.',\n",
    "    'Reference: Model Quality (+/- std)',\n",
    "    'Current: Model Quality (+/- std)',\n",
    "    'Current: Error (Predicted - Actual)',\n",
    "    'Current: Error Distribution',\n",
    "])])\n",
    "regression_perfomance_dashboard.calculate(reference, current.loc['2011-02-07 00:00:00':'2011-02-14 23:00:00'], \n",
    "                                            column_mapping=column_mapping)\n",
    "regression_perfomance_dashboard.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Week3\n",
    "regression_perfomance_dashboard.calculate(reference, current.loc['2011-02-15 00:00:00':'2011-02-21 23:00:00'], \n",
    "                                            column_mapping=column_mapping)\n",
    "regression_perfomance_dashboard.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why the quality has dropped?\n",
    "column_mapping_drift = ColumnMapping()\n",
    "\n",
    "column_mapping_drift.target = target\n",
    "column_mapping_drift.prediction = prediction\n",
    "column_mapping_drift.numerical_features = numerical_features\n",
    "column_mapping_drift.categorical_features = []\n",
    "data_drift_dashboard = Dashboard(tabs=[DataDriftTab()])\n",
    "data_drift_dashboard.calculate(reference,\n",
    "                               current.loc['2011-02-14 00:00:00':'2011-02-21 23:00:00'], \n",
    "                               column_mapping_drift\n",
    "                              )\n",
    "data_drift_dashboard.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's customize the report!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.calculations.stattests import StatTest\n",
    "\n",
    "def _anderson_stat_test(reference_data: pd.Series, current_data: pd.Series, feature_type: str, threshold: float):\n",
    "    p_value = anderson_ksamp(np.array([reference_data, current_data]))[2]\n",
    "    return p_value, p_value < threshold\n",
    "\n",
    "anderson_stat_test = StatTest(\n",
    "    name=\"anderson\",\n",
    "    display_name=\"Anderson test (p_value)\",\n",
    "    func=_anderson_stat_test,\n",
    "    allowed_feature_types=[\"num\"]\n",
    ")\n",
    "\n",
    "options = DataDriftOptions(feature_stattest_func=anderson_stat_test, nbinsx=20, confidence=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_dashboard = Dashboard(\n",
    "    tabs=[RegressionPerformanceTab(include_widgets=[\n",
    "                                    'Regression Model Performance Report.',\n",
    "                                    'Reference: Model Quality (+/- std)',\n",
    "                                    'Current: Model Quality (+/- std)',\n",
    "                                    'Current: Error (Predicted - Actual)',\n",
    "                                    'Current: Error Distribution',]\n",
    "                                  ),\n",
    "          DataDriftTab()],\n",
    "    options=[options])\n",
    "                                \n",
    "the_dashboard.calculate(reference,\n",
    "                        current.loc['2011-02-14 00:00:00':'2011-02-21 23:00:00'], \n",
    "                        column_mapping_drift)\n",
    "\n",
    "the_dashboard.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "355f3a624190feab978816587f5e67f4125bf569ad1e77316ee4902f4d408615"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
